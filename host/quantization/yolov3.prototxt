name: "Darkent2Caffe"
# layer {
# name: "data"
# type: "Input"
# top: "data"
# input_param: { shape: { dim: 1 dim: 3 dim: 224 dim: 224 } }
# }
layer {
name: "data"
type: "ImageData"
top: "data"
top: "label"
include {
  phase: TRAIN
}
transform_param {
  mirror: false
  yolo_height:224    #change height according to Darknet model
  yolo_width:224     #change width  according to Darknet model
}
image_data_param {
  source:"/workspace/darknet/Mask/calib_data.txt"         #change path accordingly
  root_folder:"/workspace/darknet/Mask/yolo/"  #change path accordingly
  batch_size: 1
  shuffle: false
}
}
layer {
    bottom: "data"
    top: "layer0-conv"
    name: "layer0-conv"
    type: "Convolution"
    convolution_param {
        num_output: 16
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer0-conv"
    top: "layer0-conv"
    name: "layer0-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer0-conv"
    top: "layer0-conv"
    name: "layer0-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer0-conv"
    top: "layer1-maxpool"
    name: "layer1-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
     }
 }
layer {
    bottom: "layer1-maxpool"
    top: "layer2-conv"
    name: "layer2-conv"
    type: "Convolution"
    convolution_param {
        num_output: 32
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer2-conv"
    top: "layer2-conv"
    name: "layer2-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer2-conv"
    top: "layer2-conv"
    name: "layer2-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer2-conv"
    top: "layer3-maxpool"
    name: "layer3-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
     }
 }
layer {
    bottom: "layer3-maxpool"
    top: "layer4-conv"
    name: "layer4-conv"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer4-conv"
    top: "layer4-conv"
    name: "layer4-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer4-conv"
    top: "layer4-conv"
    name: "layer4-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer4-conv"
    top: "layer5-maxpool"
    name: "layer5-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
     }
 }
layer {
    bottom: "layer5-maxpool"
    top: "layer6-conv"
    name: "layer6-conv"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer6-conv"
    top: "layer6-conv"
    name: "layer6-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer6-conv"
    top: "layer6-conv"
    name: "layer6-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer6-conv"
    top: "layer7-maxpool"
    name: "layer7-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
     }
 }
layer {
    bottom: "layer7-maxpool"
    top: "layer8-conv"
    name: "layer8-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer8-conv"
    top: "layer8-conv"
    name: "layer8-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer8-conv"
    top: "layer8-conv"
    name: "layer8-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer8-conv"
    top: "layer9-maxpool"
    name: "layer9-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
     }
 }
layer {
    bottom: "layer9-maxpool"
    top: "layer10-conv"
    name: "layer10-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer10-conv"
    top: "layer10-conv"
    name: "layer10-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer10-conv"
    top: "layer10-conv"
    name: "layer10-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer10-conv"
    top: "layer11-maxpool"
    name: "layer11-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 1
        stride: 1
        pool: MAX
        pad: 0
     }
 }
layer {
    bottom: "layer11-maxpool"
    top: "layer12-conv"
    name: "layer12-conv"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer12-conv"
    top: "layer12-conv"
    name: "layer12-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer12-conv"
    top: "layer12-conv"
    name: "layer12-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer12-conv"
    top: "layer13-conv"
    name: "layer13-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer13-conv"
    top: "layer13-conv"
    name: "layer13-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer13-conv"
    top: "layer13-conv"
    name: "layer13-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer13-conv"
    top: "layer14-conv"
    name: "layer14-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer14-conv"
    top: "layer14-conv"
    name: "layer14-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer14-conv"
    top: "layer14-conv"
    name: "layer14-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer14-conv"
    top: "layer15-conv"
    name: "layer15-conv"
    type: "Convolution"
    convolution_param {
        num_output: 24
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: true
     }
 }
layer {
    bottom: "layer13-conv"
    top: "layer18-conv"
    name: "layer18-conv"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer18-conv"
    top: "layer18-conv"
    name: "layer18-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer18-conv"
    top: "layer18-conv"
    name: "layer18-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer18-conv"
    top: "layer19-upsample"
    name: "layer19-upsample"
    type: "DeephiResize"
    deephi_resize_param {
        scale_h: 2
        scale_w: 2
     }
 }
layer {
    bottom: "layer19-upsample"
    bottom: "layer8-conv"
    top: "layer20-concat"
    name: "layer20-concat"
    type: "Concat"
 }
layer {
    bottom: "layer20-concat"
    top: "layer21-conv"
    name: "layer21-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
     }
 }
layer {
    bottom: "layer21-conv"
    top: "layer21-conv"
    name: "layer21-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
     }
 }
layer {
    bottom: "layer21-conv"
    top: "layer21-conv"
    name: "layer21-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
     }
 }
layer {
    bottom: "layer21-conv"
    top: "layer22-conv"
    name: "layer22-conv"
    type: "Convolution"
    convolution_param {
        num_output: 24
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: true
     }
 }
